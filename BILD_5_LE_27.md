---
course: BILD 5
type: lecture
lecture_num: 27
date: 3/12
---

# BILD 5 Lecture 27
- ## 3/12

## Machine Learning
### Supervised, Unsupervised, Shallow, and Deep?
### Era of Big Data
- **Cost of Sequencing is dropping**
- **Rate of public genome/transcriptome generation is growing**
- As technology advances, we are collecting more and more data
- This amount of data allow us to do what was unimaginable before
- Old analytical techniques are not keeping up
- Matrix-Matrix Comparisons
- Matrix of phenotypes
	- proteomics dataset
- And matrix of genome
	- plus environment
	- 
### Machine Learning Duality
#### Unsupervised learning vs supervised learning
- Unsupervised learning – 
	- finding the inherent structure within the data
- Supervised learning – 
	- making prediction of the output using a classifier or regressor
#### Unsupervised Learning
- only looking at one of the matrices
	- supervise the algorithm
##### Clustering
- Clustering – A method of grouping data together
	- best fit line forced through cloud of dots
##### Matrix Decomposition
- Matrix Decomposition – Reducing the dimensionality of the data
##### Supervised Learning
- When machines start making decisions
	- have something we know about the set
	- can better predict y with some large amount of x inputs
#### Supervised Learning
##### Simple supervised learning algorithms
- Linear regression – fitting a line to your scatterplot
	- Logistic regression
		- try to build a machine learning model that will build line
			- brute force best fit
- Trees – split the data until you arrive at the bottom
	- Decision tree
		- image captchas
		- vectorize pixels of images
		- turn into decision tree
	- *structural equation models*
		- **SEM**
		- **correlation coefficients**
			- end with single Mu parameter estimate
	- Regression tree
### Artificial Neural Networks and Deep Learning
#### Neural Networks
- Named for their structural similarity to neural synapse in our brains
- Produces some of the most powerful machine learning algorithms
	- in SEM decided what nodes were
	- here let computer decide nodes
	- provide with info and answers
	- training set
		- neural network to predict whether 0 or 1
	- useful when have a lot of info
#### Why deep learning
- lose the storytelling
##### How do machines learn?
- Neurons – Activates under certain conditions
	- logical gates
- Weights – Connects the neurons to other neurons
#### Backpropagation
1. First determine how far off the output is from the target
2.  Find the direction of change that can push output toward the target
3. Send this information upstream through the network and update the weights
##### Real life examples
- Self-driving cars
- Alphafold2
#### Course Recommendations
##### Math background courses:
- **MATH 18 (linear algebra),**
- MATH 20C & E (multivariate calculus),
- MATH 180 series (Upper div stats)
##### Machine learning courses:
- COGS 181B 
	- (Intro to machine learning – Unsupervised learning),
- COGS 181A 
	- (Simple supervised learning)
- CSE 151A 
	- (Intro to machine learning – 
		- Some unsupervised and supervised learning), 
- CSE 151B (Deep learning)


---

Previous: [BILD 5 Lecture 26](BILD_5_LE_26.md).
Next: [BILD 5 Lecture 28](BILD_5_LE_28.md).